{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9428dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#Text Cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b6e203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab218a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Срыв сроков строительства зоопарка оценили в 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>По данным Генпрокуратуры РФ, в 2014-2018 годах...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Обвиняли в этом столичный акимат, который сорв...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Запуск циклотронного центра ядерной медицины н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Сроки сдачи объекта несколько раз переносились.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  Срыв сроков строительства зоопарка оценили в 1...      1\n",
       "1  По данным Генпрокуратуры РФ, в 2014-2018 годах...      1\n",
       "2  Обвиняли в этом столичный акимат, который сорв...      1\n",
       "3  Запуск циклотронного центра ядерной медицины н...      1\n",
       "4    Сроки сдачи объекта несколько раз переносились.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"input/train_data.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e3b2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1340\n",
      "1     329\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of Labels')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df['label'].value_counts())\n",
    "df['label'].value_counts().plot.bar()\n",
    "plt.title('Distribution of Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1709fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\"seed\": 2021,\n",
    "          \"epochs\": 4,\n",
    "          \"model_name\": \"DeepPavlov/rubert-base-cased\",\n",
    "          \"train_batch_size\": 24,\n",
    "          \"valid_batch_size\": 46,\n",
    "          \"max_length\": 100,\n",
    "          \"learning_rate\": 1e-5,\n",
    "          \"epsilon\" : 1e-6,\n",
    "          \"weight_decay\": 1e-5,\n",
    "          \"n_fold\": 5,\n",
    "          \"num_classes\": 1,\n",
    "          \"patience\": 2,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          }\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28967ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80b5700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_train, df_valid = train_test_split(df, test_size=0.2, random_state=CONFIG['seed'])\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_train, df_valid = train_test_split(df, test_size=0.2, random_state=CONFIG['seed'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40b15d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_train = df_train.reset_index(drop=True)\\ndf_valid = df_valid.reset_index(drop=True)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_train = df_train.reset_index(drop=True)\n",
    "df_valid = df_valid.reset_index(drop=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1933ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_train.head()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_train.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ead45fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_valid.head()'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_valid.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9f7d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61cbfb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentence = df.sentence.apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4c74e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Срыв сроков строительства зоопарка оценили в 1...\n",
       "1       По данным Генпрокуратуры РФ, в 2014-2018 годах...\n",
       "2       Обвиняли в этом столичный акимат, который сорв...\n",
       "3       Запуск циклотронного центра ядерной медицины н...\n",
       "4         Сроки сдачи объекта несколько раз переносились.\n",
       "                              ...                        \n",
       "1664    Подрядчик ООО «АльянсДорСтрой» должен сдать об...\n",
       "1665    Он заявил, что запуск ракеты-носителя сверхтяж...\n",
       "1666    Застройщик ЖК \"Медовая Долина\" планирует ввест...\n",
       "1667    Официальные сроки, указанные в проектной декла...\n",
       "1668    Он потребовал «выдержать намеченные сроки» стр...\n",
       "Name: sentence, Length: 1669, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49d9f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Срыв сроков строительства зоопарка оценили в 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>По данным Генпрокуратуры РФ, в 2014-2018 годах...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Обвиняли в этом столичный акимат, который сорв...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Запуск циклотронного центра ядерной медицины н...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Сроки сдачи объекта несколько раз переносились.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  kfold\n",
       "0  Срыв сроков строительства зоопарка оценили в 1...      1      4\n",
       "1  По данным Генпрокуратуры РФ, в 2014-2018 годах...      1      3\n",
       "2  Обвиняли в этом столичный акимат, который сорв...      1      3\n",
       "3  Запуск циклотронного центра ядерной медицины н...      1      4\n",
       "4    Сроки сдачи объекта несколько раз переносились.      1      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(skf.split(X=df.sentence, y=df.label)):\n",
    "    df.loc[val_ , \"kfold\"] = int(fold)\n",
    "    \n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52627f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Срыв сроков строительства зоопарка оценили в 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>По данным Генпрокуратуры РФ, в 2014-2018 годах...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Обвиняли в этом столичный акимат, который сорв...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Запуск циклотронного центра ядерной медицины н...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Сроки сдачи объекта несколько раз переносились.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>Подрядчик ООО «АльянсДорСтрой» должен сдать об...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>Он заявил, что запуск ракеты-носителя сверхтяж...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>Застройщик ЖК \"Медовая Долина\" планирует ввест...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>Официальные сроки, указанные в проектной декла...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>Он потребовал «выдержать намеченные сроки» стр...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  kfold\n",
       "0     Срыв сроков строительства зоопарка оценили в 1...      1      4\n",
       "1     По данным Генпрокуратуры РФ, в 2014-2018 годах...      1      3\n",
       "2     Обвиняли в этом столичный акимат, который сорв...      1      3\n",
       "3     Запуск циклотронного центра ядерной медицины н...      1      4\n",
       "4       Сроки сдачи объекта несколько раз переносились.      1      1\n",
       "...                                                 ...    ...    ...\n",
       "1664  Подрядчик ООО «АльянсДорСтрой» должен сдать об...      0      1\n",
       "1665  Он заявил, что запуск ракеты-носителя сверхтяж...      0      3\n",
       "1666  Застройщик ЖК \"Медовая Долина\" планирует ввест...      0      3\n",
       "1667  Официальные сроки, указанные в проектной декла...      0      2\n",
       "1668  Он потребовал «выдержать намеченные сроки» стр...      0      0\n",
       "\n",
       "[1669 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692659b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ba9ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SberNewsDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = df.sentence\n",
    "        self.targets = df['label']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                                text,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length',\n",
    "                                return_token_type_ids=True\n",
    "                            )\n",
    "        target = np.array(self.targets[index])\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.int),\n",
    "            'mask': torch.tensor(mask, dtype=torch.int),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.int),\n",
    "            'target': torch.tensor(target, dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22d229d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SberNewsModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(SberNewsModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, CONFIG['num_classes'])\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, features = self.model(input_ids=ids, attention_mask=mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        out = self.drop(features)\n",
    "        outputs = self.fc(out)\n",
    "        \n",
    "        return outputs.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d83617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = compute_class_weight(class_weight = 'balanced', classes = [0, 1], y = df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7c49d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62276119, 2.53647416])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "814ddca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, targets):\n",
    "    weights = torch.as_tensor(class_weight,dtype=torch.float).to(CONFIG['device'])\n",
    "    return torch.nn.BCEWithLogitsLoss(pos_weight=weights[1])(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8a4e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    #Automatic Mixed Precision\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    #------------------\n",
    "    \n",
    "    score_batch = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "            \n",
    "        \n",
    "        ids = data['ids'].to(device, dtype = torch.int)\n",
    "        mask = data['mask'].to(device, dtype = torch.int)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.int)\n",
    "        targets = data['target'].to(device, dtype=torch.float)\n",
    "\n",
    "        batch_size = ids.size(0)\n",
    "\n",
    "        #Automatic Mixed Precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "        #------------------\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            #print(outputs)\n",
    "            #print(targets)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            \n",
    "        \n",
    "        #Automatic Mixed Precision\n",
    "        scaler.scale(loss).backward()\n",
    "        #------------------\n",
    "\n",
    "                \n",
    "        #optimizer.step()\n",
    "            \n",
    "        #Automatic Mixed Precision\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        #------------------\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                            LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "febba625",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    accuracy_batch = []\n",
    "    balanced_accuracy_score_batch = []\n",
    "    \n",
    "    epoch_targets=[]\n",
    "    epoch_outputs=[]\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        ids = data['ids'].to(device, dtype = torch.int)\n",
    "        mask = data['mask'].to(device, dtype = torch.int)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.int)\n",
    "        targets = data['target'].to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = ids.size(0)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        #print(f\"outputs ({outputs})\")\n",
    "        epoch_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "        epoch_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "        \n",
    "        #print(f\"out_detach_sigmoid ({out_detach_sigmoid})\")\n",
    "        #print(f\"targets_detach ({targets_detach})\")\n",
    "        \n",
    "        #print(f\"accuracy_batch ({accuracy_batch})\")\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        epoch_accuracy = np.mean(accuracy_batch)\n",
    "        epoch_balanced_accuracy_score = np.mean(balanced_accuracy_score_batch)\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    return epoch_loss, epoch_outputs, epoch_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5ae106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, device, num_epochs, fold):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer,  \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss, epoch_outputs, epoch_targets = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "        #print(f\"Validation epoch_outputs ({epoch_outputs})\")\n",
    "        #print(f\"Validation epoch_targets ({epoch_targets})\")\n",
    "        \n",
    "        roc_auc_score = metrics.roc_auc_score(epoch_targets, epoch_outputs)\n",
    "        \n",
    "        epoch_outputs = np.array(epoch_outputs) >= 0.5\n",
    "        accuracy_score = metrics.accuracy_score(epoch_targets, epoch_outputs)\n",
    "        balanced_accuracy_score = metrics.balanced_accuracy_score(epoch_targets, epoch_outputs)\n",
    "        f1_score = metrics.f1_score(epoch_targets, epoch_outputs)\n",
    "        recall_score = metrics.recall_score(epoch_targets, epoch_outputs)\n",
    "        precision_score = metrics.precision_score(epoch_targets, epoch_outputs)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        print(f\"Validation roc auc score ({roc_auc_score})\")\n",
    "        print(f\"Validation accuracy ({accuracy_score})\")\n",
    "        print(f\"Validation balanced accuracy score ({balanced_accuracy_score})\")\n",
    "        print(f\"Validation f1 score ({f1_score})\")\n",
    "        print(f\"Validation recall score ({recall_score})\")\n",
    "        print(f\"Validation precision score ({precision_score})\")\n",
    "        \n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            history[\"Best Loss\"].append(best_epoch_loss)\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"Loss-Fold-{fold}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= CONFIG[\"patience\"]:\n",
    "                print('Early stopping!' )\n",
    "                print()\n",
    "                break\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "454d1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders():\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = SberNewsDataset(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    valid_dataset = SberNewsDataset(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=True, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99525e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Fold: 0 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.55it/s, Epoch=1, LR=1e-5, Train_Loss=0.792]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.75it/s, Epoch=1, LR=1e-5, Valid_Loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.8631275440976933)\n",
      "Validation accuracy (0.6497005988023952)\n",
      "Validation balanced accuracy score (0.7588760741745817)\n",
      "Validation f1 score (0.5145228215767634)\n",
      "Validation recall score (0.9393939393939394)\n",
      "Validation precision score (0.35428571428571426)\n",
      "Validation Loss Improved (inf ---> 0.7341574366221171)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.55it/s, Epoch=2, LR=1e-5, Train_Loss=0.555]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.74it/s, Epoch=2, LR=1e-5, Valid_Loss=0.483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9164970601537766)\n",
      "Validation accuracy (0.8562874251497006)\n",
      "Validation balanced accuracy score (0.8704771596562642)\n",
      "Validation f1 score (0.7108433734939759)\n",
      "Validation recall score (0.8939393939393939)\n",
      "Validation precision score (0.59)\n",
      "Validation Loss Improved (0.7341574366221171 ---> 0.48252162256997505)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.54it/s, Epoch=3, LR=1e-5, Train_Loss=0.337]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.75it/s, Epoch=3, LR=1e-5, Valid_Loss=0.455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9227725011307101)\n",
      "Validation accuracy (0.8592814371257484)\n",
      "Validation balanced accuracy score (0.8780529172320217)\n",
      "Validation f1 score (0.718562874251497)\n",
      "Validation recall score (0.9090909090909091)\n",
      "Validation precision score (0.594059405940594)\n",
      "Validation Loss Improved (0.48252162256997505 ---> 0.4551903463141647)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.52it/s, Epoch=4, LR=1e-5, Train_Loss=0.217]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.61it/s, Epoch=4, LR=1e-5, Valid_Loss=0.415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9272388059701493)\n",
      "Validation accuracy (0.8982035928143712)\n",
      "Validation balanced accuracy score (0.8737562189054726)\n",
      "Validation f1 score (0.7638888888888888)\n",
      "Validation recall score (0.8333333333333334)\n",
      "Validation precision score (0.7051282051282052)\n",
      "Validation Loss Improved (0.4551903463141647 ---> 0.414642235598789)\n",
      "Model Saved\n",
      "\n",
      "Training complete in 0h 0m 51s\n",
      "Best Loss: 0.4146\n",
      "\n",
      "====== Fold: 1 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.56it/s, Epoch=1, LR=1e-5, Train_Loss=0.839]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.70it/s, Epoch=1, LR=1e-5, Valid_Loss=0.674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.8690355042966984)\n",
      "Validation accuracy (0.8473053892215568)\n",
      "Validation balanced accuracy score (0.7107078245137947)\n",
      "Validation f1 score (0.5565217391304348)\n",
      "Validation recall score (0.48484848484848486)\n",
      "Validation precision score (0.6530612244897959)\n",
      "Validation Loss Improved (inf ---> 0.6742365965229309)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.53it/s, Epoch=2, LR=1e-5, Train_Loss=0.556]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.68it/s, Epoch=2, LR=1e-5, Valid_Loss=0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9321573948439621)\n",
      "Validation accuracy (0.781437125748503)\n",
      "Validation balanced accuracy score (0.8295454545454546)\n",
      "Validation f1 score (0.6217616580310881)\n",
      "Validation recall score (0.9090909090909091)\n",
      "Validation precision score (0.47244094488188976)\n",
      "Validation Loss Improved (0.6742365965229309 ---> 0.4856384145820926)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.53it/s, Epoch=3, LR=1e-5, Train_Loss=0.329]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.45it/s, Epoch=3, LR=1e-5, Valid_Loss=0.402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9473654454997739)\n",
      "Validation accuracy (0.8562874251497006)\n",
      "Validation balanced accuracy score (0.8761872455902306)\n",
      "Validation f1 score (0.7142857142857143)\n",
      "Validation recall score (0.9090909090909091)\n",
      "Validation precision score (0.5882352941176471)\n",
      "Validation Loss Improved (0.4856384145820926 ---> 0.4019253405625235)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.48it/s, Epoch=4, LR=1e-5, Train_Loss=0.199]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.52it/s, Epoch=4, LR=1e-5, Valid_Loss=0.536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9374151967435549)\n",
      "Validation accuracy (0.8832335329341318)\n",
      "Validation balanced accuracy score (0.8358774310266848)\n",
      "Validation f1 score (0.7194244604316548)\n",
      "Validation recall score (0.7575757575757576)\n",
      "Validation precision score (0.684931506849315)\n",
      "\n",
      "Training complete in 0h 0m 49s\n",
      "Best Loss: 0.4019\n",
      "\n",
      "====== Fold: 2 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.37it/s, Epoch=1, LR=1e-5, Train_Loss=0.854]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.23it/s, Epoch=1, LR=1e-5, Valid_Loss=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.837347354138399)\n",
      "Validation accuracy (0.8173652694610778)\n",
      "Validation balanced accuracy score (0.5550090456806875)\n",
      "Validation f1 score (0.2077922077922078)\n",
      "Validation recall score (0.12121212121212122)\n",
      "Validation precision score (0.7272727272727273)\n",
      "Validation Loss Improved (inf ---> 0.7413224010410423)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████| 56/56 [00:10<00:00,  5.23it/s, Epoch=2, LR=1e-5, Train_Loss=0.57]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.65it/s, Epoch=2, LR=1e-5, Valid_Loss=0.414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9486657620985979)\n",
      "Validation accuracy (0.8772455089820359)\n",
      "Validation balanced accuracy score (0.8664066033469019)\n",
      "Validation f1 score (0.7320261437908496)\n",
      "Validation recall score (0.8484848484848485)\n",
      "Validation precision score (0.6436781609195402)\n",
      "Validation Loss Improved (0.7413224010410423 ---> 0.41406211993116104)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.44it/s, Epoch=3, LR=1e-5, Train_Loss=0.331]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.60it/s, Epoch=3, LR=1e-5, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9579941203075532)\n",
      "Validation accuracy (0.8952095808383234)\n",
      "Validation balanced accuracy score (0.8433401175938489)\n",
      "Validation f1 score (0.7407407407407408)\n",
      "Validation recall score (0.7575757575757576)\n",
      "Validation precision score (0.7246376811594203)\n",
      "Validation Loss Improved (0.41406211993116104 ---> 0.3928098385027069)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.45it/s, Epoch=4, LR=1e-5, Train_Loss=0.208]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.63it/s, Epoch=4, LR=1e-5, Valid_Loss=0.435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9615558570782451)\n",
      "Validation accuracy (0.9041916167664671)\n",
      "Validation balanced accuracy score (0.8603573043871551)\n",
      "Validation f1 score (0.7647058823529412)\n",
      "Validation recall score (0.7878787878787878)\n",
      "Validation precision score (0.7428571428571429)\n",
      "\n",
      "Training complete in 0h 0m 51s\n",
      "Best Loss: 0.3928\n",
      "\n",
      "====== Fold: 3 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.43it/s, Epoch=1, LR=1e-5, Train_Loss=0.839]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.65it/s, Epoch=1, LR=1e-5, Valid_Loss=0.758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.8985753052917231)\n",
      "Validation accuracy (0.8562874251497006)\n",
      "Validation balanced accuracy score (0.6534938941655359)\n",
      "Validation f1 score (0.4666666666666667)\n",
      "Validation recall score (0.3181818181818182)\n",
      "Validation precision score (0.875)\n",
      "Validation Loss Improved (inf ---> 0.7576700386529911)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.40it/s, Epoch=2, LR=1e-5, Train_Loss=0.477]\n",
      "100%|██████████| 8/8 [00:01<00:00,  7.56it/s, Epoch=2, LR=1e-5, Valid_Loss=0.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9752374491180462)\n",
      "Validation accuracy (0.9311377245508982)\n",
      "Validation balanced accuracy score (0.9171189507010402)\n",
      "Validation f1 score (0.8368794326241135)\n",
      "Validation recall score (0.8939393939393939)\n",
      "Validation precision score (0.7866666666666666)\n",
      "Validation Loss Improved (0.7576700386529911 ---> 0.2803470654312722)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.39it/s, Epoch=3, LR=1e-5, Train_Loss=0.272]\n",
      "100%|██████████| 8/8 [00:01<00:00,  7.38it/s, Epoch=3, LR=1e-5, Valid_Loss=0.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9757462686567164)\n",
      "Validation accuracy (0.9131736526946108)\n",
      "Validation balanced accuracy score (0.917345092718227)\n",
      "Validation f1 score (0.8079470198675496)\n",
      "Validation recall score (0.9242424242424242)\n",
      "Validation precision score (0.7176470588235294)\n",
      "Validation Loss Improved (0.2803470654312722 ---> 0.2703412109818644)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.31it/s, Epoch=4, LR=1e-5, Train_Loss=0.169]\n",
      "100%|██████████| 8/8 [00:01<00:00,  7.65it/s, Epoch=4, LR=1e-5, Valid_Loss=0.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9794210764360017)\n",
      "Validation accuracy (0.937125748502994)\n",
      "Validation balanced accuracy score (0.9151402080506559)\n",
      "Validation f1 score (0.8467153284671534)\n",
      "Validation recall score (0.8787878787878788)\n",
      "Validation precision score (0.8169014084507042)\n",
      "Validation Loss Improved (0.2703412109818644 ---> 0.25028800724553846)\n",
      "Model Saved\n",
      "\n",
      "Training complete in 0h 0m 52s\n",
      "Best Loss: 0.2503\n",
      "\n",
      "====== Fold: 4 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.47it/s, Epoch=1, LR=1e-5, Train_Loss=0.866]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.82it/s, Epoch=1, LR=1e-5, Valid_Loss=0.788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.7609070034443168)\n",
      "Validation accuracy (0.7447447447447447)\n",
      "Validation balanced accuracy score (0.6724454649827785)\n",
      "Validation f1 score (0.45859872611464975)\n",
      "Validation recall score (0.5538461538461539)\n",
      "Validation precision score (0.391304347826087)\n",
      "Validation Loss Improved (inf ---> 0.787885778301113)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████| 56/56 [00:10<00:00,  5.43it/s, Epoch=2, LR=1e-5, Train_Loss=0.64]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.35it/s, Epoch=2, LR=1e-5, Valid_Loss=0.455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.922158438576349)\n",
      "Validation accuracy (0.8678678678678678)\n",
      "Validation balanced accuracy score (0.8421641791044776)\n",
      "Validation f1 score (0.7027027027027027)\n",
      "Validation recall score (0.8)\n",
      "Validation precision score (0.6265060240963856)\n",
      "Validation Loss Improved (0.787885778301113 ---> 0.455302093211595)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 56/56 [00:10<00:00,  5.46it/s, Epoch=3, LR=1e-5, Train_Loss=0.347]\n",
      "100%|██████████| 8/8 [00:01<00:00,  7.76it/s, Epoch=3, LR=1e-5, Valid_Loss=0.46]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9270952927669346)\n",
      "Validation accuracy (0.8888888888888888)\n",
      "Validation balanced accuracy score (0.8610505166475315)\n",
      "Validation f1 score (0.7412587412587412)\n",
      "Validation recall score (0.8153846153846154)\n",
      "Validation precision score (0.6794871794871795)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████| 56/56 [00:10<00:00,  5.37it/s, Epoch=4, LR=1e-5, Train_Loss=0.251]\n",
      "100%|█████████| 8/8 [00:01<00:00,  7.68it/s, Epoch=4, LR=1e-5, Valid_Loss=0.442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation roc auc score (0.9373134328358208)\n",
      "Validation accuracy (0.8948948948948949)\n",
      "Validation balanced accuracy score (0.8647818599311137)\n",
      "Validation f1 score (0.7517730496453899)\n",
      "Validation recall score (0.8153846153846154)\n",
      "Validation precision score (0.6973684210526315)\n",
      "Validation Loss Improved (0.455302093211595 ---> 0.44229314007513876)\n",
      "Model Saved\n",
      "\n",
      "Training complete in 0h 0m 50s\n",
      "Best Loss: 0.4423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in range(0, CONFIG['n_fold']):\n",
    "    print(f\"====== Fold: {fold} ======\")\n",
    "    \n",
    "    # Create Dataloaders\n",
    "    train_loader, valid_loader = prepare_loaders()\n",
    "    \n",
    "    model = SberNewsModel(CONFIG['model_name'])\n",
    "    model.to(CONFIG['device'])\n",
    "    \n",
    "    # Define Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], eps=CONFIG['epsilon'], weight_decay=CONFIG['weight_decay'])\n",
    "    \n",
    "    model, history = run_training(model, optimizer,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=fold)\n",
    "    \n",
    "    \n",
    "    del model, history, train_loader, valid_loader\n",
    "    _ = gc.collect()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e26a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
